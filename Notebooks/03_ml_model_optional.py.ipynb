{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e05746e-0036-4731-82bf-756e4aadce8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8049048207453833\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>severity</th><th>prediction</th><th>probability</th></tr></thead><tbody><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.4974015709904159\",\"0.3429964310916133\",\"0.15226175894264424\",\"0.0073402389753264565\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}</td></tr><tr><td>2</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6987953217026853\",\"0.2812102559099847\",\"0.011851941102997199\",\"0.008142481284332783\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6987953217026853\",\"0.2812102559099847\",\"0.011851941102997199\",\"0.008142481284332783\"]}</td></tr><tr><td>3</td><td>0.0</td><td>{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6987953217026853\",\"0.2812102559099847\",\"0.011851941102997199\",\"0.008142481284332783\"]}</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.4974015709904159\",\"0.3429964310916133\",\"0.15226175894264424\",\"0.0073402389753264565\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.7116156048098043\",\"0.27007873743692234\",\"0.011190503853486501\",\"0.00711515389978685\"]}"
        ],
        [
         2,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6987953217026853\",\"0.2812102559099847\",\"0.011851941102997199\",\"0.008142481284332783\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6987953217026853\",\"0.2812102559099847\",\"0.011851941102997199\",\"0.008142481284332783\"]}"
        ],
        [
         3,
         0.0,
         "{\"type\":\"1\",\"size\":null,\"indices\":null,\"values\":[\"0.6987953217026853\",\"0.2812102559099847\",\"0.011851941102997199\",\"0.008142481284332783\"]}"
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "severity",
         "type": "\"integer\""
        },
        {
         "metadata": "{\"ml_attr\": {\"num_vals\": 4, \"type\": \"nominal\"}}",
         "name": "prediction",
         "type": "\"double\""
        },
        {
         "metadata": "{\"ml_attr\": {\"num_attrs\": 4}}",
         "name": "probability",
         "type": "{\"class\":\"org.apache.spark.ml.linalg.VectorUDT\",\"pyClass\":\"pyspark.ml.linalg.VectorUDT\",\"sqlType\":{\"fields\":[{\"metadata\":{},\"name\":\"type\",\"nullable\":false,\"type\":\"byte\"},{\"metadata\":{},\"name\":\"size\",\"nullable\":true,\"type\":\"integer\"},{\"metadata\":{},\"name\":\"indices\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"integer\",\"type\":\"array\"}},{\"metadata\":{},\"name\":\"values\",\"nullable\":true,\"type\":{\"containsNull\":false,\"elementType\":\"double\",\"type\":\"array\"}}],\"type\":\"struct\"},\"type\":\"udt\"}"
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Databricks notebook: 03_ml_model_optional.py\n",
    "# Purpose: Train a simple ML model (RandomForestClassifier) to predict accident severity\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "DATABASE = 'madsc102'\n",
    "TABLE = 'usaccidents_volume'\n",
    "FULL_TABLE = f\"{DATABASE}.{TABLE}\"\n",
    "\n",
    "\n",
    "df = spark.table(FULL_TABLE)\n",
    "\n",
    "\n",
    "# Select features for prediction\n",
    "features = ['start_hour', 'distance_miles', 'duration_minutes', 'is_weekend']\n",
    "\n",
    "\n",
    "# Handle nulls\n",
    "for col in features:\n",
    " df = df.fillna({col: 0})\n",
    "\n",
    "\n",
    "# Feature vector\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "df_vec = assembler.transform(df)\n",
    "\n",
    "\n",
    "# Prepare label\n",
    "indexer = StringIndexer(inputCol='severity', outputCol='label')\n",
    "df_final = indexer.fit(df_vec).transform(df_vec)\n",
    "\n",
    "\n",
    "# Train/test split\n",
    "train, test = df_final.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol='features', labelCol='label', numTrees=50)\n",
    "model = rf.fit(train)\n",
    "\n",
    "\n",
    "preds = model.transform(test)\n",
    "\n",
    "\n",
    "eval_acc = MulticlassClassificationEvaluator(labelCol='label', metricName='accuracy')\n",
    "print('Accuracy:', eval_acc.evaluate(preds))\n",
    "\n",
    "\n",
    "# Show sample predictions\n",
    "display(preds.select('severity', 'prediction', 'probability').limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e75b099-40d3-405b-a177-4218a84412a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ML Job...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8102768085781944>, line 3\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Simulated job run\u001B[39;00m\n",
       "\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting ML Job...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m----> 3\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mnotebook\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m60\u001B[39m)\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mML Job completed successfully!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:327\u001B[0m, in \u001B[0;36mDBUtils.NotebookHandler.run\u001B[0;34m(self, path, timeout_seconds, arguments, *args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m arguments_scala_map: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]\n",
       "\u001B[1;32m    325\u001B[0m arguments_scala_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjvm\u001B[38;5;241m.\u001B[39morg\u001B[38;5;241m.\u001B[39mapache\u001B[38;5;241m.\u001B[39mspark\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mpython\u001B[38;5;241m.\u001B[39mPythonUtils\u001B[38;5;241m.\u001B[39mtoScalaMap(\n",
       "\u001B[1;32m    326\u001B[0m     arguments)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n",
       "\u001B[0;32m--> 327\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetDbutils()\u001B[38;5;241m.\u001B[39mnotebook()\u001B[38;5;241m.\u001B[39mrun(\n",
       "\u001B[1;32m    328\u001B[0m     path, timeout_seconds, arguments_scala_map, __databricks_internal_cluster_spec)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1362\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1356\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1357\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1358\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1359\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1361\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1362\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n",
       "\u001B[1;32m   1363\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n",
       "\u001B[1;32m   1365\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py:327\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    325\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    326\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 327\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    329\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    331\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    333\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o108.run.\n",
       ": com.databricks.WorkflowException: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n",
       "\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:98)\n",
       "\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n",
       "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:197)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:117)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
       "Caused by: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n",
       "\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:146)\n",
       "\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:93)\n",
       "\t... 13 more\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "Py4JJavaError",
        "evalue": "An error occurred while calling o108.run.\n: com.databricks.WorkflowException: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:98)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:197)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:117)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:146)\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:93)\n\t... 13 more\n"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>Py4JJavaError</span>: An error occurred while calling o108.run.\n: com.databricks.WorkflowException: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:98)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:197)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:117)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:146)\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:93)\n\t... 13 more\n"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m<command-8102768085781944>, line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Simulated job run\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStarting ML Job...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m dbutils\u001B[38;5;241m.\u001B[39mnotebook\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m60\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mML Job completed successfully!\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
        "File \u001B[0;32m/databricks/python_shell/lib/dbruntime/dbutils.py:327\u001B[0m, in \u001B[0;36mDBUtils.NotebookHandler.run\u001B[0;34m(self, path, timeout_seconds, arguments, *args, **kwargs)\u001B[0m\n\u001B[1;32m    324\u001B[0m arguments_scala_map: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m]\n\u001B[1;32m    325\u001B[0m arguments_scala_map \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjvm\u001B[38;5;241m.\u001B[39morg\u001B[38;5;241m.\u001B[39mapache\u001B[38;5;241m.\u001B[39mspark\u001B[38;5;241m.\u001B[39mapi\u001B[38;5;241m.\u001B[39mpython\u001B[38;5;241m.\u001B[39mPythonUtils\u001B[38;5;241m.\u001B[39mtoScalaMap(\n\u001B[1;32m    326\u001B[0m     arguments)  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[0;32m--> 327\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentry_point\u001B[38;5;241m.\u001B[39mgetDbutils()\u001B[38;5;241m.\u001B[39mnotebook()\u001B[38;5;241m.\u001B[39mrun(\n\u001B[1;32m    328\u001B[0m     path, timeout_seconds, arguments_scala_map, __databricks_internal_cluster_spec)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/java_gateway.py:1362\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1356\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1357\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1358\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1359\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1361\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1362\u001B[0m return_value \u001B[38;5;241m=\u001B[39m get_return_value(\n\u001B[1;32m   1363\u001B[0m     answer, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_id, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mname)\n\u001B[1;32m   1365\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1366\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.9-src.zip/py4j/protocol.py:327\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    325\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    326\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 327\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    329\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    331\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    333\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
        "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o108.run.\n: com.databricks.WorkflowException: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:98)\n\tat com.databricks.dbutils_v1.impl.NotebookUtilsImpl.run(NotebookUtilsImpl.scala:130)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:77)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:569)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:197)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:117)\n\tat java.base/java.lang.Thread.run(Thread.java:840)\nCaused by: com.databricks.NotebookExecutionException: FAILED: Unable to access the notebook \"/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional\". Either it does not exist, or the identity used to run this job, aleenaclarethomas20@gmail.com, lacks the required permissions.\n\tat com.databricks.workflow.WorkflowDriver.run0(WorkflowDriver.scala:146)\n\tat com.databricks.workflow.WorkflowDriver.run(WorkflowDriver.scala:93)\n\t... 13 more\n"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simulated job run\n",
    "print(\"Starting ML Job...\")\n",
    "dbutils.notebook.run('/Workspace/Users/aleenaclarethomas20@gmail.com/notebooks/03_ml_model_optional', 60)\n",
    "print(\"ML Job completed successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_ml_model_optional.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}